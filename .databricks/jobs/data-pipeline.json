{
  "name": "scap-data-pipeline",
  "description": "Complete data pipeline for Navigator Supply Chain Lakehouse",
  "max_concurrent_runs": 1,
  "timeout_seconds": 7200,
  "tasks": [
    {
      "task_key": "bronze_ingestion",
      "description": "Ingest raw data into bronze layer",
      "python_wheel_task": {
        "package_name": "scap",
        "entry_point": "run_pipeline",
        "parameters": [
          "--stage", "bronze"
        ]
      },
      "serverless": true,
      "environment_key": "default"
    },
    {
      "task_key": "silver_conformance",
      "description": "Process data through silver layer with conformance rules",
      "python_wheel_task": {
        "package_name": "scap",
        "entry_point": "run_pipeline",
        "parameters": [
          "--stage", "silver"
        ]
      },
      "serverless": true,
      "environment_key": "default",
      "depends_on": [
        {
          "task_key": "bronze_ingestion"
        }
      ]
    },
    {
      "task_key": "gold_publish",
      "description": "Publish final data to gold layer",
      "python_wheel_task": {
        "package_name": "scap",
        "entry_point": "run_pipeline",
        "parameters": [
          "--stage", "gold"
        ]
      },
      "serverless": true,
      "environment_key": "default",
      "depends_on": [
        {
          "task_key": "silver_conformance"
        }
      ]
    }
  ],
  "environments": [
    {
      "environment_key": "default",
      "name": "default",
      "spec": {
        "client": "2",
        "dependencies": [
          "databricks-sdk",
          "great-expectations"
        ]
      }
    }
  ],
  "tags": {
    "project": "scap",
    "environment": "default",
    "component": "pipeline"
  }
}
